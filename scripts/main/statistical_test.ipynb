{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67a47d9-8778-4db5-94be-173846cbd6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "from scipy.stats import pearsonr, gaussian_kde, linregress, ttest_ind, sem, zscore\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from math import factorial\n",
    "from more_itertools import distinct_permutations\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, ParameterGrid, train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "#from torch.utils.data import SubsetRandomSampler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#import pingouin as pg\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f900438a-5584-4fff-9a39-e23c7e4d1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannot import add_stat_annotation\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efa6ad8-8649-46c1-90ec-50d776c582c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils import check_random_state\n",
    "from itertools import islice\n",
    "\n",
    "def permtest(x, y, statistic=\"mean\", max_samples=5000, random_state=42):\n",
    "    \"\"\"\n",
    "    Conducts a permutation test between two independent samples.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        First set of datapoints.\n",
    "    y : ndarray\n",
    "        Second set of datapoints.\n",
    "    statistic : str or callable, optional\n",
    "        Function that takes in samples x and y and reports\n",
    "        statistic of interest. By default, \"mean\" reports\n",
    "        the difference of sample means. List of default\n",
    "        options are (\"mean\", \"median\").\n",
    "    max_samples : int, optional.\n",
    "        Maximum number of label permutations to try.\n",
    "    random_state : np.random.RandomState, int, or None.\n",
    "        If specified, used to seed the random number generator to shuffle the ordering of the datapoints.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize random state and function of interest\n",
    "    rs = check_random_state(random_state)\n",
    "    stat_func = _get_stat_func(statistic)\n",
    "\n",
    "    # Concatenate samples\n",
    "    xy = np.concatenate((x, y))\n",
    "    n_x = x.size\n",
    "\n",
    "    # Observed statistic\n",
    "    observed_stat = stat_func(x, y)\n",
    "\n",
    "    # Set the number of permutations to compute\n",
    "    n_perms = max(max_samples, 100000)  # Limit the number of permutations to a manageable number (e.g., 10000)\n",
    "\n",
    "    # Allocate space for computed statistics\n",
    "    shuffled_stats = np.empty(n_perms)\n",
    "\n",
    "    # Print coverage\n",
    "    print(f\"Computing permutations...\")\n",
    "\n",
    "    # Sampling random permutations\n",
    "    for i in range(n_perms):\n",
    "        rs.shuffle(xy)\n",
    "        x_ = xy[:n_x]\n",
    "        y_ = xy[n_x:]\n",
    "        shuffled_stats[i] = stat_func(x_, y_)\n",
    "\n",
    "    # Compute a two-sided p-value. We take the smallest\n",
    "    # percentile and then multiply by two.\n",
    "    pval = 2 * min(\n",
    "        percentileofscore(shuffled_stats, observed_stat, kind=\"rank\") / 100,\n",
    "        1 - percentileofscore(shuffled_stats, observed_stat, kind=\"rank\") / 100\n",
    "    )\n",
    "\n",
    "    return pval\n",
    "\n",
    "def _get_stat_func(name_or_func):\n",
    "    \"\"\"\n",
    "    Instantiates functions that compute default statistics of interest.\n",
    "    \"\"\"\n",
    "    # If specified function is callable\n",
    "    if not isinstance(name_or_func, str):\n",
    "        if callable(name_or_func):\n",
    "            return name_or_func\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`statistic` should be a string like ('mean', 'median')\"\n",
    "                \" or a function that takes in samples x, y and returns\"\n",
    "                \" the statistic of interest.\"\n",
    "            )\n",
    "\n",
    "    # Default functions\n",
    "    if name_or_func == \"mean\":\n",
    "        return lambda x, y: np.mean(x) - np.mean(y)\n",
    "    elif name_or_func == \"median\":\n",
    "        return lambda x, y: np.median(x) - np.median(y)\n",
    "    else:\n",
    "        raise ValueError(\"Did not recognize statistic.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9768cde7-edc7-4225-80a1-000a4255676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pooled(x, y, func):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    return np.sqrt(((nx - 1) * func(x) ** 2 + (ny - 1) * func(y) ** 2) / (nx + ny - 2))\n",
    "\n",
    "def hdmedian(x):\n",
    "    return np.median(x)\n",
    "\n",
    "def hdmad(x):\n",
    "    return 1.4826 * hdmedian(np.abs(x - hdmedian(x)))\n",
    "\n",
    "def phdmad(x, y):\n",
    "    return pooled(x, y, hdmad)\n",
    "\n",
    "def gamma_effect_size(x, y, prob):\n",
    "    hdquantile_x = np.percentile(x, prob * 100)\n",
    "    hdquantile_y = np.percentile(y, prob * 100)\n",
    "    return (hdquantile_y - hdquantile_x) / phdmad(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4965c642-c438-4aa7-b472-65253d4a1355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr_01(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "    ir_mult = 0.1\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def remove_outliers_iqr_05(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "    ir_mult = 0.5\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def remove_outliers_iqr_10(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    ir_mult = 1.0\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def cliff_delta(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_01(group1)\n",
    "    group2_ = remove_outliers_iqr_01(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis]  \n",
    "        group2_exp = group2[np.newaxis, :]  \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "def cliff_delta05(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_05(group1)\n",
    "    group2_ = remove_outliers_iqr_05(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis]  \n",
    "        group2_exp = group2[np.newaxis, :] \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "def cliff_delta10(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_10(group1)\n",
    "    group2_ = remove_outliers_iqr_10(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis]  \n",
    "        group2_exp = group2[np.newaxis, :]  \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "\n",
    "def calculate_z_from_u(group1, group2, u_statistic):\n",
    "    group1 = remove_outliers_iqr(group1)\n",
    "    group2 = remove_outliers_iqr(group2)\n",
    "\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    mu_u = (n1 * n2) / 2\n",
    "    sigma_u = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
    "\n",
    "    z_value = (u_statistic - mu_u) / sigma_u\n",
    "\n",
    "    r_value = z_value / np.sqrt(n1 + n2)\n",
    "\n",
    "    return r_value\n",
    "\n",
    "\n",
    "def rank_biserial_from_u(group1, group2):\n",
    "    group1 = remove_outliers_iqr_01(group1)\n",
    "    group2 = remove_outliers_iqr_01(group2)\n",
    "\n",
    "    u_statistic, _ = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    r_biserial = 1 - (2 * u_statistic) / (n1 * n2)\n",
    "\n",
    "    return r_biserial\n",
    "\n",
    "def rank_biserial_from_u10(group1, group2):\n",
    "    group1 = remove_outliers_iqr_10(group1)\n",
    "    group2 = remove_outliers_iqr_10(group2)\n",
    "\n",
    "    u_statistic, _ = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    r_biserial = 1 - (2 * u_statistic) / (n1 * n2)\n",
    "\n",
    "    return r_biserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d41b7f-3ad9-4dfb-a99d-3d40588707f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a775ac2-8294-48fc-a011-2f75c514204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAGs_data = pd.read_excel('data/BAGs_for_statistical_test.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde70502-9a1f-446e-9708-fb3285064571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 12426 6213 6213\n",
      "cliff delta -0.1995 0.0\n",
      "N 17054 8527 8527\n",
      "N 20056 10028 10028\n",
      "No parametric cliff_delta: -0.200\n",
      "Computing permutations...\n",
      "N 200 100 100\n",
      "cliff delta -0.5596 0.0\n",
      "N 284 142 142\n",
      "N 324 162 162\n",
      "No parametric cliff_delta: -0.560\n",
      "Computing permutations...\n",
      "N 12590 6295 6295\n",
      "cliff delta 0.3093 0.0\n",
      "N 17658 8829 8829\n",
      "N 20442 10221 10221\n",
      "No parametric cliff_delta: 0.309\n",
      "Computing permutations...\n",
      "N 202 101 101\n",
      "cliff delta -0.4216 0.0\n",
      "N 280 140 140\n",
      "N 324 162 162\n",
      "No parametric cliff_delta: -0.422\n",
      "Computing permutations...\n",
      "N 42434 21217 21217\n",
      "cliff delta 0.5408 0.0\n",
      "N 58440 29220 29220\n",
      "N 68730 34365 34365\n",
      "No parametric cliff_delta: 0.541\n",
      "Computing permutations...\n",
      "N 202 101 101\n",
      "cliff delta 0.7263 0.0\n",
      "N 282 141 141\n",
      "N 324 162 162\n",
      "No parametric cliff_delta: 0.726\n",
      "Computing permutations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>p-value 100000 perm</th>\n",
       "      <th>p-value mann whitney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asia</td>\n",
       "      <td>LatinAmerica</td>\n",
       "      <td>0.1995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.087436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.5596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3169</td>\n",
       "      <td>0.297122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1857</td>\n",
       "      <td>0.189314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LatinAmerica</td>\n",
       "      <td>Africa</td>\n",
       "      <td>0.4216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.260264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LatinAmerica</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.288315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Africa</td>\n",
       "      <td>Europa</td>\n",
       "      <td>0.7263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4736</td>\n",
       "      <td>0.413351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Group1        Group2  cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0          Asia  LatinAmerica                                          0.1995   \n",
       "1          Asia        Africa                                          0.5596   \n",
       "2          Asia        Europa                                          0.3093   \n",
       "3  LatinAmerica        Africa                                          0.4216   \n",
       "4  LatinAmerica        Europa                                          0.5408   \n",
       "5        Africa        Europa                                          0.7263   \n",
       "\n",
       "   CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "5                                    0.0   \n",
       "\n",
       "   cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.1363   \n",
       "1                                          0.3636   \n",
       "2                                          0.2241   \n",
       "3                                          0.2770   \n",
       "4                                          0.3956   \n",
       "5                                          0.3743   \n",
       "\n",
       "   CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "5                                    0.0   \n",
       "\n",
       "   cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.0910   \n",
       "1                                          0.3169   \n",
       "2                                          0.1857   \n",
       "3                                          0.3219   \n",
       "4                                          0.2890   \n",
       "5                                          0.4736   \n",
       "\n",
       "   CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  p-value 100000 perm  \\\n",
       "0                               0.087436                  0.0   \n",
       "1                               0.297122                  0.0   \n",
       "2                               0.189314                  0.0   \n",
       "3                               0.260264                  0.0   \n",
       "4                               0.288315                  0.0   \n",
       "5                               0.413351                  0.0   \n",
       "\n",
       "   p-value mann whitney  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  \n",
       "3                   0.0  \n",
       "4                   0.0  \n",
       "5                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "order = ['Europe', 'Asia', 'LatinAmerica', 'Africa']\n",
    "\n",
    "regions = BAGs_data['Region1'].unique()\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = BAGs_data[BAGs_data['Region1'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = BAGs_data[BAGs_data['Region1'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "\n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd81bb30-ee00-4127-9c47-01ebb4ba393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliff_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96acedb-4255-4dd6-afbc-d10be7d59988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 17994 8997 8997\n",
      "cliff delta -0.1363 0.0\n",
      "N 25234 12617 12617\n",
      "N 29440 14720 14720\n",
      "No parametric cliff_delta: -0.136\n",
      "No parametric biseral: 0.128\n",
      "Computing permutations...\n",
      "N 13486 6743 6743\n",
      "cliff delta -0.0454 0.0\n",
      "N 18966 9483 9483\n",
      "N 22150 11075 11075\n",
      "No parametric cliff_delta: -0.045\n",
      "No parametric biseral: 0.038\n",
      "Computing permutations...\n",
      "N 11896 5948 5948\n",
      "cliff delta -0.2257 0.0\n",
      "N 16730 8365 8365\n",
      "N 19532 9766 9766\n",
      "No parametric cliff_delta: -0.226\n",
      "No parametric biseral: 0.233\n",
      "Computing permutations...\n",
      "N 13640 6820 6820\n",
      "cliff delta 0.0947 0.0\n",
      "N 19380 9690 9690\n",
      "N 22370 11185 11185\n",
      "No parametric cliff_delta: 0.095\n",
      "No parametric biseral: -0.094\n",
      "Computing permutations...\n",
      "N 12172 6086 6086\n",
      "cliff delta -0.1001 0.0\n",
      "N 17242 8621 8621\n",
      "N 19774 9887 9887\n",
      "No parametric cliff_delta: -0.100\n",
      "No parametric biseral: 0.102\n",
      "Computing permutations...\n",
      "N 12026 6013 6013\n",
      "cliff delta -0.1838 0.0\n",
      "N 17052 8526 8526\n",
      "N 19696 9848 9848\n",
      "No parametric cliff_delta: -0.184\n",
      "No parametric biseral: 0.194\n",
      "Computing permutations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>p-value 100000 perm</th>\n",
       "      <th>p-value mann whitney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WesternEurope</td>\n",
       "      <td>EasternEurope</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WesternEurope</td>\n",
       "      <td>NorthernEurope</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.018047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WesternEurope</td>\n",
       "      <td>SouthernEurope</td>\n",
       "      <td>0.2257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.137311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EasternEurope</td>\n",
       "      <td>NorthernEurope</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.053918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EasternEurope</td>\n",
       "      <td>SouthernEurope</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.065898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NorthernEurope</td>\n",
       "      <td>SouthernEurope</td>\n",
       "      <td>0.1838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.118086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Group1          Group2  \\\n",
       "0   WesternEurope   EasternEurope   \n",
       "1   WesternEurope  NorthernEurope   \n",
       "2   WesternEurope  SouthernEurope   \n",
       "3   EasternEurope  NorthernEurope   \n",
       "4   EasternEurope  SouthernEurope   \n",
       "5  NorthernEurope  SouthernEurope   \n",
       "\n",
       "   cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.1363   \n",
       "1                                          0.0454   \n",
       "2                                          0.2257   \n",
       "3                                          0.0947   \n",
       "4                                          0.1001   \n",
       "5                                          0.1838   \n",
       "\n",
       "   CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "5                                    0.0   \n",
       "\n",
       "   cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.0769   \n",
       "1                                          0.0202   \n",
       "2                                          0.1425   \n",
       "3                                          0.0551   \n",
       "4                                          0.0712   \n",
       "5                                          0.1195   \n",
       "\n",
       "   CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "5                                    0.0   \n",
       "\n",
       "   cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.0709   \n",
       "1                                          0.0171   \n",
       "2                                          0.1369   \n",
       "3                                          0.0548   \n",
       "4                                          0.0600   \n",
       "5                                          0.1202   \n",
       "\n",
       "   CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  p-value 100000 perm  \\\n",
       "0                               0.072300                  0.0   \n",
       "1                               0.018047                  0.0   \n",
       "2                               0.137311                  0.0   \n",
       "3                               0.053918                  0.0   \n",
       "4                               0.065898                  0.0   \n",
       "5                               0.118086                  0.0   \n",
       "\n",
       "   p-value mann whitney  \n",
       "0               0.00000  \n",
       "1               0.00536  \n",
       "2               0.00000  \n",
       "3               0.00000  \n",
       "4               0.00000  \n",
       "5               0.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "BAGs_data_europe = BAGs_data[BAGs_data['Region1'] == 'Europa']\n",
    "\n",
    "\n",
    "order = ['WesternEurope', 'EasternEurope', 'NorthernEurope', 'SouthernEurope']\n",
    "\n",
    "\n",
    "BAGs_data_no_outliers = BAGs_data_europe\n",
    "\n",
    "order = ['WesternEurope', 'EasternEurope', 'NorthernEurope', 'SouthernEurope']\n",
    "\n",
    "\n",
    "regions = BAGs_data_no_outliers['Region'].unique()\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Region'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Region'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        \n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "        print(f\"No parametric biseral: {r_b:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff9bf7f-0914-4773-8e73-d1a7a321efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 51748 25874 25874\n",
      "cliff delta 0.5687 0.0\n",
      "N 72264 36132 36132\n",
      "N 84984 42492 42492\n",
      "No parametric cliff_delta: 0.569\n",
      "No parametric biseral: -0.571\n",
      "Computing permutations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>p-value 100000 perm</th>\n",
       "      <th>p-value mann whitney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L_GDP</td>\n",
       "      <td>H_GDP</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.300884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group1 Group2  cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0  L_GDP  H_GDP                                          0.5687   \n",
       "\n",
       "   CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.4096   \n",
       "\n",
       "   CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                           0.301   \n",
       "\n",
       "   CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  p-value 100000 perm  \\\n",
       "0                               0.300884                  0.0   \n",
       "\n",
       "   p-value mann whitney  \n",
       "0                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "q1 = BAGs_data['GAP_corrected'].quantile(0.25)\n",
    "q3 = BAGs_data['GAP_corrected'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.0 * iqr\n",
    "upper_bound = q3 + 1.0 * iqr\n",
    "\n",
    "\n",
    "BAGs_data_no_outliers = BAGs_data\n",
    "\n",
    "bins = [0, BAGs_data['GDP_percapita'].median(), float('inf')]  # Umbrales en dólares\n",
    "labels = ['L_GDP', 'H_GDP']\n",
    "\n",
    "\n",
    "BAGs_data_no_outliers['Group_GDP'] = pd.cut(BAGs_data_no_outliers['GDP_percapita'], bins=bins, labels=labels)\n",
    "\n",
    "order = ['L_GDP', 'H_GDP']\n",
    "\n",
    "regions = ['L_GDP', 'H_GDP']\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Group_GDP'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Group_GDP'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        \n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "        print(f\"No parametric biseral: {r_b:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c42ef601-d5b4-4dec-a975-4bd7d73a464e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17402.03761280788"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BAGs_data['GDP_percapita'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c414cc0-4bdd-4386-966c-4281a96e4270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 57726 28863 28863\n",
      "cliff delta -0.5728 0.0\n",
      "N 80670 40335 40335\n",
      "N 94490 47245 47245\n",
      "No parametric cliff_delta: -0.573\n",
      "Computing permutations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>p-value 100000 perm</th>\n",
       "      <th>p-value mann whitney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L_Ineq</td>\n",
       "      <td>H_Ineq</td>\n",
       "      <td>0.5728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>0.300884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Group1  Group2  cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0  L_Ineq  H_Ineq                                          0.5728   \n",
       "\n",
       "   CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.4054   \n",
       "\n",
       "   CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.3055   \n",
       "\n",
       "   CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  p-value 100000 perm  \\\n",
       "0                               0.300884                  0.0   \n",
       "\n",
       "   p-value mann whitney  \n",
       "0                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "q1 = BAGs_data['GAP_corrected'].quantile(0.25)\n",
    "q3 = BAGs_data['GAP_corrected'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.0 * iqr\n",
    "upper_bound = q3 + 1.0 * iqr\n",
    "\n",
    "BAGs_data_no_outliers = BAGs_data\n",
    "\n",
    "order = ['L_Ineq', 'H_Ineq']\n",
    "\n",
    "regions = ['L_Ineq', 'H_Ineq']\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Group_GINI'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = BAGs_data_no_outliers[BAGs_data_no_outliers['Group_GINI'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        \n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a71761-06f1-44a8-abfc-883faacf0349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31bdf7e-6c50-4f69-8a2c-7eb2cff01617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b6c18b-cb77-491e-a04b-1f5a35ac63ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N 26168 13084 13084\n",
      "cliff delta -0.4897 0.0\n",
      "N 35638 17819 17819\n",
      "N 41572 20786 20786\n",
      "No parametric cliff_delta: -0.490\n",
      "No parametric biseral: 0.493\n",
      "Computing permutations...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group1</th>\n",
       "      <th>Group2</th>\n",
       "      <th>cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)</th>\n",
       "      <th>p-value 100000 perm</th>\n",
       "      <th>p-value mann whitney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H</td>\n",
       "      <td>L</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2619</td>\n",
       "      <td>0.260627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group1 Group2  cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0      H      L                                          0.4897   \n",
       "\n",
       "   CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.3452   \n",
       "\n",
       "   CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                    0.0   \n",
       "\n",
       "   cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  \\\n",
       "0                                          0.2619   \n",
       "\n",
       "   CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)  p-value 100000 perm  \\\n",
       "0                               0.260627                  0.0   \n",
       "\n",
       "   p-value mann whitney  \n",
       "0                   0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "q1 = BAGs_data['GAP_corrected'].quantile(0.25)\n",
    "q3 = BAGs_data['GAP_corrected'].quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "lower_bound = q1 - 1.0 * iqr\n",
    "upper_bound = q3 + 1.0 * iqr\n",
    "\n",
    "BAGs_data_no_outliers = BAGs_data\n",
    "\n",
    "BAGs_data_no_outliers.loc[BAGs_data_no_outliers['country'] == 'Colombia', 'Income'] = 'L'\n",
    "BAGs_data_no_outliers.loc[BAGs_data_no_outliers['country'] == 'Ecuador', 'Income'] = 'L'\n",
    "BAGs_data_no_outliers.loc[BAGs_data_no_outliers['country'] == 'Brasil', 'Income'] = 'L'\n",
    "BAGs_data_no_outliers.loc[BAGs_data_no_outliers['country'] == 'Italy', 'Income'] = 'H'\n",
    "\n",
    "\n",
    "BAGs_data_no_outliers['Income_v1'] = BAGs_data_no_outliers['Income'] \n",
    "\n",
    "BAGs_data_no_outliers['Income_v1'] = BAGs_data_no_outliers['Income_v1'].replace({'UM':'H'})\n",
    "\n",
    "order = ['H', 'L']\n",
    "\n",
    "regions = ['H', 'L']\n",
    "mann_whitney_results = []\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = BAGs_data[BAGs_data['Income_v1'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = BAGs_data[BAGs_data['Income_v1'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "    \n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "        print(f\"No parametric biseral: {r_b:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "    \n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864e2b3-a6e8-4cdd-9a76-98a10cd79619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
