{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy import stats\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7eafbd-6b07-446d-9876-c0e3929f1953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "from sklearn.utils import check_random_state\n",
    "from itertools import islice\n",
    "\n",
    "def permtest(x, y, statistic=\"mean\", max_samples=5000, random_state=42):\n",
    "    \"\"\"\n",
    "    Conducts a permutation test between two independent samples.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        First set of datapoints.\n",
    "    y : ndarray\n",
    "        Second set of datapoints.\n",
    "    statistic : str or callable, optional\n",
    "        Function that takes in samples x and y and reports\n",
    "        statistic of interest. By default, \"mean\" reports\n",
    "        the difference of sample means. List of default\n",
    "        options are (\"mean\", \"median\").\n",
    "    max_samples : int, optional.\n",
    "        Maximum number of label permutations to try.\n",
    "    random_state : np.random.RandomState, int, or None.\n",
    "        If specified, used to seed the random number generator to shuffle the ordering of the datapoints.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize random state and function of interest\n",
    "    rs = check_random_state(random_state)\n",
    "    stat_func = _get_stat_func(statistic)\n",
    "\n",
    "    # Concatenate samples\n",
    "    xy = np.concatenate((x, y))\n",
    "    n_x = x.size\n",
    "\n",
    "    # Observed statistic\n",
    "    observed_stat = stat_func(x, y)\n",
    "\n",
    "    # Set the number of permutations to compute\n",
    "    n_perms = max(max_samples, 100000)  # Limit the number of permutations to a manageable number (e.g., 10000)\n",
    "\n",
    "    # Allocate space for computed statistics\n",
    "    shuffled_stats = np.empty(n_perms)\n",
    "\n",
    "    # Print coverage\n",
    "    print(f\"Computing permutations...\")\n",
    "\n",
    "    # Sampling random permutations\n",
    "    for i in range(n_perms):\n",
    "        rs.shuffle(xy)\n",
    "        x_ = xy[:n_x]\n",
    "        y_ = xy[n_x:]\n",
    "        shuffled_stats[i] = stat_func(x_, y_)\n",
    "\n",
    "    # Compute a two-sided p-value. We take the smallest\n",
    "    # percentile and then multiply by two.\n",
    "    pval = 2 * min(\n",
    "        percentileofscore(shuffled_stats, observed_stat, kind=\"rank\") / 100,\n",
    "        1 - percentileofscore(shuffled_stats, observed_stat, kind=\"rank\") / 100\n",
    "    )\n",
    "\n",
    "    return pval\n",
    "\n",
    "def _get_stat_func(name_or_func):\n",
    "    \"\"\"\n",
    "    Instantiates functions that compute default statistics of interest.\n",
    "    \"\"\"\n",
    "    # If specified function is callable\n",
    "    if not isinstance(name_or_func, str):\n",
    "        if callable(name_or_func):\n",
    "            return name_or_func\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`statistic` should be a string like ('mean', 'median')\"\n",
    "                \" or a function that takes in samples x, y and returns\"\n",
    "                \" the statistic of interest.\"\n",
    "            )\n",
    "\n",
    "    # Default functions\n",
    "    if name_or_func == \"mean\":\n",
    "        return lambda x, y: np.mean(x) - np.mean(y)\n",
    "    elif name_or_func == \"median\":\n",
    "        return lambda x, y: np.median(x) - np.median(y)\n",
    "    else:\n",
    "        raise ValueError(\"Did not recognize statistic.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee0dd7d-e21c-4fd7-b820-a934356335ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pooled(x, y, func):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    return np.sqrt(((nx - 1) * func(x) ** 2 + (ny - 1) * func(y) ** 2) / (nx + ny - 2))\n",
    "\n",
    "def hdmedian(x):\n",
    "    return np.median(x)\n",
    "\n",
    "def hdmad(x):\n",
    "    return 1.4826 * hdmedian(np.abs(x - hdmedian(x)))\n",
    "\n",
    "def phdmad(x, y):\n",
    "    return pooled(x, y, hdmad)\n",
    "\n",
    "def gamma_effect_size(x, y, prob):\n",
    "    hdquantile_x = np.percentile(x, prob * 100)\n",
    "    hdquantile_y = np.percentile(y, prob * 100)\n",
    "    return (hdquantile_y - hdquantile_x) / phdmad(x, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f10b22c-cd11-42f7-8418-b3373209d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr_01(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "    ir_mult = 0.1\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def remove_outliers_iqr_05(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "\n",
    "    ir_mult = 0.5\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def remove_outliers_iqr_10(data):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    ir_mult = 1.0\n",
    "    lower_bound = Q1 - ir_mult * IQR\n",
    "    upper_bound = Q3 + ir_mult * IQR\n",
    "\n",
    "    filtered_data = data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "def cliff_delta(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_01(group1)\n",
    "    group2_ = remove_outliers_iqr_01(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis]  \n",
    "        group2_exp = group2[np.newaxis, :]  \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "def cliff_delta05(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_05(group1)\n",
    "    group2_ = remove_outliers_iqr_05(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis] \n",
    "        group2_exp = group2[np.newaxis, :]  \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "def cliff_delta10(group1, group2):\n",
    "\n",
    "    group1_ = remove_outliers_iqr_10(group1)\n",
    "    group2_ = remove_outliers_iqr_10(group2)\n",
    "    \n",
    "    sub_sample_size = np.min([int(group1_.shape[0]*0.7), int(group2_.shape[0]*0.7)])\n",
    "\n",
    "\n",
    "    delta_l = []\n",
    "    for i in range(10):\n",
    "       \n",
    "        group1 = resample(group1_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "        group2 = resample(group2_, n_samples=sub_sample_size, replace=False, random_state=i)\n",
    "    \n",
    "        group1_exp = group1[:, np.newaxis]  \n",
    "        group2_exp = group2[np.newaxis, :]   \n",
    "    \n",
    "        greater = np.sum(group1_exp > group2_exp)\n",
    "        less = np.sum(group1_exp < group2_exp)\n",
    "    \n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        delta = (greater - less) / (n1 * n2)\n",
    "\n",
    "    delta_l.append(delta)\n",
    "\n",
    "    print('N', n1+n2, n1, n2)\n",
    "\n",
    "    return (np.round(np.mean(delta_l), 4), np.round(np.std(delta_l)*2.58,100))\n",
    "\n",
    "\n",
    "def calculate_z_from_u(group1, group2, u_statistic):\n",
    "    group1 = remove_outliers_iqr(group1)\n",
    "    group2 = remove_outliers_iqr(group2)\n",
    "\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    mu_u = (n1 * n2) / 2\n",
    "    sigma_u = np.sqrt((n1 * n2 * (n1 + n2 + 1)) / 12)\n",
    "\n",
    "    z_value = (u_statistic - mu_u) / sigma_u\n",
    "\n",
    "    r_value = z_value / np.sqrt(n1 + n2)\n",
    "\n",
    "    return r_value\n",
    "\n",
    "\n",
    "def rank_biserial_from_u(group1, group2):\n",
    "    group1 = remove_outliers_iqr_01(group1)\n",
    "    group2 = remove_outliers_iqr_01(group2)\n",
    "\n",
    "    u_statistic, _ = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    r_biserial = 1 - (2 * u_statistic) / (n1 * n2)\n",
    "\n",
    "    return r_biserial\n",
    "\n",
    "def rank_biserial_from_u10(group1, group2):\n",
    "    group1 = remove_outliers_iqr_10(group1)\n",
    "    group2 = remove_outliers_iqr_10(group2)\n",
    "\n",
    "    u_statistic, _ = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "\n",
    "    r_biserial = 1 - (2 * u_statistic) / (n1 * n2)\n",
    "\n",
    "    return r_biserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac60e2c9-0f6d-431e-b880-a497f41ddc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f40c2-14a3-4a70-8288-6161c96cd911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43250906-1216-4f54-bf2a-1dddb2789fe8",
   "metadata": {},
   "source": [
    "## SES with education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c16b1-9147-43fd-94a1-a709ba4ab50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_merge_wo_nan =  pd.read_excel('data/SES_data.xlsx')\n",
    "pd_merge_wo_nan = pd_merge_wo_nan.dropna(subset=['SES_wo_w'])\n",
    "pd_merge_wo_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc278572-3e9e-4957-a696-f633c4363260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907e886-c630-41f4-8882-b133e5a51afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge_df_all = pd_merge_wo_nan.copy()\n",
    "\n",
    "\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "\n",
    "bef = results_merge_df_all.shape[0]\n",
    "\n",
    "Q1 = results_merge_df_all['GAP_corrected'].quantile(0.25)\n",
    "Q3 = results_merge_df_all['GAP_corrected'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "results_merge_df_all['z_score'] = stats.zscore(results_merge_df_all['GAP_corrected'])\n",
    "\n",
    "outliers = results_merge_df_all[(results_merge_df_all['GAP_corrected'] < lower_bound) | (results_merge_df_all['GAP_corrected'] > upper_bound)]\n",
    "outliers2 = results_merge_df_all[(results_merge_df_all['z_score'] > 3) | (results_merge_df_all['z_score'] < -3)]\n",
    "\n",
    "\n",
    "results_merge_df_all = results_merge_df_all[(results_merge_df_all['GAP_corrected'] >= lower_bound) & (results_merge_df_all['GAP_corrected'] <= upper_bound)]\n",
    "\n",
    "results_merge_df_all = results_merge_df_all.dropna(subset=['SES_wo_w', 'GAP_corrected'])\n",
    "\n",
    "\n",
    "gb_region = results_merge_df_all.groupby(['Region_x'])['GAP_corrected'].agg(['mean', 'std', 'median']).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "aft = results_merge_df_all.shape[0]\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "display(100*aft/bef)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(6.7,6.7))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "sns.scatterplot(x='SES_wo_w', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['SES_wo_w'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['SES_wo_w'], intercept + slope * results_merge_df_all['SES_wo_w'], color='blue')\n",
    "plt.ylim([-12, 12])\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e2bec-b9e5-4bdc-80f8-4c128860dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge_df_all = pd_merge_wo_nan.copy()\n",
    "\n",
    "results_merge_df_all = results_merge_df_all.dropna(subset=['gender_equal_l',\n",
    "                                                            'Migration',\n",
    "                                                            'Polution_conc_inv',\n",
    "                                                            'Eq',\n",
    "                                                            'free_parties_l',\n",
    "                                                            'inclu_suff_est',\n",
    "                                                            'cred_elect_est',\n",
    "                                                            'local_dem_est'])\n",
    "\n",
    "\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "\n",
    "bef = results_merge_df_all.shape[0]\n",
    "\n",
    "Q1 = results_merge_df_all['GAP_corrected'].quantile(0.25)\n",
    "Q3 = results_merge_df_all['GAP_corrected'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "results_merge_df_all['z_score'] = stats.zscore(results_merge_df_all['GAP_corrected'])\n",
    "\n",
    "outliers = results_merge_df_all[(results_merge_df_all['GAP_corrected'] < lower_bound) | (results_merge_df_all['GAP_corrected'] > upper_bound)]\n",
    "outliers2 = results_merge_df_all[(results_merge_df_all['z_score'] > 3) | (results_merge_df_all['z_score'] < -3)]\n",
    "\n",
    "\n",
    "results_merge_df_all = results_merge_df_all[(results_merge_df_all['GAP_corrected'] >= lower_bound) & (results_merge_df_all['GAP_corrected'] <= upper_bound)]\n",
    "\n",
    "results_merge_df_all.reset_index(inplace = True, drop = True)\n",
    "\n",
    "aft = results_merge_df_all.shape[0]\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "display(100*aft/bef)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "vars_physical = ['gender_equal_l', 'Migration', 'Polution_conc_inv', 'Eq']\n",
    "\n",
    "vars_extended = ['free_parties_l',  'inclu_suff_est', 'cred_elect_est', 'local_dem_est']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "results_merge_df_all[vars_physical] = scaler.fit_transform(results_merge_df_all[vars_physical])\n",
    "results_merge_df_all['physical'] = results_merge_df_all[vars_physical].mean(axis=1)\n",
    "\n",
    "results_merge_df_all[vars_extended] = scaler.fit_transform(results_merge_df_all[vars_extended])\n",
    "results_merge_df_all['extended'] = results_merge_df_all[vars_extended].mean(axis=1)\n",
    "\n",
    "total_exposomes = vars_physical + vars_extended\n",
    "results_merge_df_all[total_exposomes] = scaler.fit_transform(results_merge_df_all[total_exposomes])\n",
    "results_merge_df_all['total_exposomes'] = results_merge_df_all[total_exposomes].mean(axis=1)\n",
    "\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(6.7,2.7))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "sns.scatterplot(x='physical', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['physical'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['physical'], intercept + slope * results_merge_df_all['physical'], color='blue')\n",
    "#plt.title(f'r = {r_value:.2f} p = {p_value:.2e}')\n",
    "\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.scatterplot(x='extended', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['extended'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['extended'], intercept + slope * results_merge_df_all['extended'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "sns.scatterplot(x='total_exposomes', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['total_exposomes'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['total_exposomes'], intercept + slope * results_merge_df_all['total_exposomes'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cceb470-d222-4a04-a8fb-014f9d6876ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_merge_df_all = pd_merge_wo_nan.copy()\n",
    "\n",
    "results_merge_df_all = results_merge_df_all.dropna(subset=['gender_equal_l',\n",
    "                                                            'Migration',\n",
    "                                                            'Polution_conc_inv',\n",
    "                                                            'Eq',\n",
    "                                                            'free_parties_l',\n",
    "                                                            'inclu_suff_est',\n",
    "                                                            'cred_elect_est',\n",
    "                                                            'local_dem_est'])\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "\n",
    "bef = results_merge_df_all.shape[0]\n",
    "\n",
    "Q1 = results_merge_df_all['GAP_corrected'].quantile(0.25)\n",
    "Q3 = results_merge_df_all['GAP_corrected'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "results_merge_df_all['z_score'] = stats.zscore(results_merge_df_all['GAP_corrected'])\n",
    "\n",
    "outliers = results_merge_df_all[(results_merge_df_all['GAP_corrected'] < lower_bound) | (results_merge_df_all['GAP_corrected'] > upper_bound)]\n",
    "outliers2 = results_merge_df_all[(results_merge_df_all['z_score'] > 3) | (results_merge_df_all['z_score'] < -3)]\n",
    "\n",
    "\n",
    "results_merge_df_all = results_merge_df_all[(results_merge_df_all['GAP_corrected'] >= lower_bound) & (results_merge_df_all['GAP_corrected'] <= upper_bound)]\n",
    "\n",
    "\n",
    "results_merge_df_all.reset_index(inplace = True, drop = True)\n",
    "\n",
    "aft = results_merge_df_all.shape[0]\n",
    "\n",
    "display(results_merge_df_all.shape)\n",
    "display(100*aft/bef)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "plt.figure(figsize=(6.7,6.7))\n",
    "\n",
    "plt.subplot(3,3,1)\n",
    "sns.scatterplot(x='gender_equal_l', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['gender_equal_l'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['gender_equal_l'], intercept + slope * results_merge_df_all['gender_equal_l'], color='blue')\n",
    "#plt.title(f'r = {r_value:.2f} p = {p_value:.2e}')\n",
    "\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "plt.subplot(3,3,2)\n",
    "sns.scatterplot(x='Migration', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['Migration'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['Migration'], intercept + slope * results_merge_df_all['Migration'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,3,3)\n",
    "sns.scatterplot(x='Polution_conc_inv', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['Polution_conc_inv'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['Polution_conc_inv'], intercept + slope * results_merge_df_all['Polution_conc_inv'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,4)\n",
    "sns.scatterplot(x='Eq', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['Eq'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['Eq'], intercept + slope * results_merge_df_all['Eq'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,5)\n",
    "sns.scatterplot(x='representation_l', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['representation_l'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['representation_l'], intercept + slope * results_merge_df_all['representation_l'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,6)\n",
    "sns.scatterplot(x='free_parties_l', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['free_parties_l'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['free_parties_l'], intercept + slope * results_merge_df_all['free_parties_l'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "\n",
    "plt.subplot(3,3,7)\n",
    "sns.scatterplot(x='inclu_suff_est', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['inclu_suff_est'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['inclu_suff_est'], intercept + slope * results_merge_df_all['inclu_suff_est'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,8)\n",
    "sns.scatterplot(x='cred_elect_est', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['cred_elect_est'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['cred_elect_est'], intercept + slope * results_merge_df_all['cred_elect_est'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "\n",
    "plt.subplot(3,3,9)\n",
    "sns.scatterplot(x='local_dem_est', y='GAP_corrected', data=results_merge_df_all, alpha=0.7, color='gray')\n",
    "slope, intercept, r_value, p_value, std_err = linregress(results_merge_df_all['local_dem_est'], results_merge_df_all['GAP_corrected'])\n",
    "plt.plot(results_merge_df_all['local_dem_est'], intercept + slope * results_merge_df_all['local_dem_est'], color='blue')\n",
    "r_value1 = np.abs(r_value)\n",
    "d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "plt.title( f'd-cohen={d_cohen:.2f} \\nr={r_value:.2f} p={p_value:.2e}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e649a8-da88-4eaa-804f-3d9bde32f9f2",
   "metadata": {},
   "source": [
    "### Co-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4b2d5-2807-4812-8145-aa524fb15334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats as stats\n",
    "import pingouin as pg\n",
    "\n",
    "subset=['gender_equal_l',\n",
    "        'Migration',\n",
    "        'Polution_conc_inv',\n",
    "        'Eq',\n",
    "        'free_parties_l',\n",
    "        'inclu_suff_est',\n",
    "        'cred_elect_est',\n",
    "        'local_dem_est', 'total_exposomes', 'extended', 'physical', 'GAP_corrected', 'representation_l', 'SES_wo_w']\n",
    "\n",
    "\n",
    "\n",
    "combined_exposomes_comb_ = [['total_exposomes', 'SES_wo_w'],\n",
    "                            ['physical', 'SES_wo_w'],\n",
    "                            ['extended', 'SES_wo_w'],\n",
    "                            ['gender_equal_l', 'SES_wo_w'],\n",
    "                            ['Migration', 'SES_wo_w'],\n",
    "                            ['Eq', 'SES_wo_w'],\n",
    "                            ['Polution_conc_inv', 'SES_wo_w'],\n",
    "                             ['representation_l', 'SES_wo_w'],\n",
    "                            ['free_parties_l', 'SES_wo_w'],\n",
    "                            ['inclu_suff_est', 'SES_wo_w'],\n",
    "                            ['cred_elect_est', 'SES_wo_w'],\n",
    "                            ['local_dem_est', 'SES_wo_w'],\n",
    "                          ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "combined_exposomes_comb_results = {}\n",
    "\n",
    "for i in combined_exposomes_comb_:\n",
    "\n",
    "    df = pd_merge_wo_nan.copy()\n",
    "\n",
    "\n",
    "    vars_physical = ['gender_equal_l', 'Migration', 'Polution_conc_inv', 'Eq']\n",
    "    \n",
    "    vars_extended = ['free_parties_l',  'inclu_suff_est', 'cred_elect_est', 'local_dem_est']\n",
    "    \n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df[vars_physical] = scaler.fit_transform(df[vars_physical])\n",
    "    df['physical'] = df[vars_physical].mean(axis=1)\n",
    "    \n",
    "    df[vars_extended] = scaler.fit_transform(df[vars_extended])\n",
    "    df['extended'] = df[vars_extended].mean(axis=1)\n",
    "    \n",
    "    total_exposomes = vars_physical + vars_extended\n",
    "    df[total_exposomes] = scaler.fit_transform(df[total_exposomes])\n",
    "    df['total_exposomes'] = df[total_exposomes].mean(axis=1)\n",
    "\n",
    "    df =  df[subset]\n",
    "\n",
    "    if( i[0] == 'Polution_conc_inv'):\n",
    "        Q1 = df[i[0]].quantile(0.25)\n",
    "        Q3 = df[i[0]].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        df = df[(df[i[0]] >= lower_bound) & (df[i[0]] <= upper_bound)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[subset], df['GAP_corrected'], test_size=0.1, random_state=42)\n",
    "\n",
    "    X_train.reset_index(inplace= True, drop = True)\n",
    "    X = X_train[i]\n",
    "    y = X_train['GAP_corrected']\n",
    "    \n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=40)\n",
    "    \n",
    "    y_labels = []\n",
    "    y_predicts = []\n",
    "    \n",
    "    \n",
    "    iter_ = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "    \n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        model = sm.OLS(y_train, X_train).fit()\n",
    "    \n",
    "        predicted_values = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "        y_labels.extend(list(y_test))\n",
    "        y_predicts.extend(list(predicted_values))\n",
    "\n",
    "\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "\n",
    "    coefficients = model.params\n",
    "    t_values = model.tvalues\n",
    "    p_values = model.pvalues\n",
    "    \n",
    "    results_summary = pd.DataFrame({\n",
    "        'Predictor': coefficients.index,  \n",
    "        'Coefficient': coefficients.values,  \n",
    "        't-Value': t_values.values, \n",
    "        'p-Value': p_values.values \n",
    "    })\n",
    "     \n",
    "    \n",
    "    r_squared = r2_score(y_labels, y_predicts)\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "\n",
    "    partial_corr = pg.partial_corr(data=df, x=i[0], y='GAP_corrected', covar=i[1])\n",
    "\n",
    "    r_value = partial_corr.loc['pearson', 'r']\n",
    "    p_value = partial_corr.loc['pearson', 'p-val']\n",
    "    r_value_pred, p_value_pred = stats.pearsonr(y_labels, y_predicts)\n",
    "\n",
    "    r_value1 = np.abs(r_value)\n",
    "    d_cohen = (2 * r_value1) / np.sqrt(1 - r_value1**2)\n",
    "\n",
    "    results_summary = pd.DataFrame({\n",
    "        'Predictor': coefficients.index,  \n",
    "        'Coefficient': coefficients.values,  \n",
    "        't-Value': t_values.values, \n",
    "        'p-Value': p_values.values, \n",
    "        'd_cohen': d_cohen, \n",
    "        'p_value_glob': p_value  \n",
    "    })\n",
    "\n",
    "    combined_exposomes_comb_results['_'.join(i)] = [y_labels, y_predicts, r_value, p_value, results_summary, r_value_pred, p_value_pred]\n",
    "    \n",
    "    print(f\"r en el conjunto de prueba: {'_'.join(i):s} {r_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40edfcf5-05a4-46c2-8cf3-a71e1672782d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97371f91-cc69-4b2b-aa3d-caf4455bb178",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c25880-e849-4557-b4ca-c368a411c941",
   "metadata": {},
   "source": [
    "#### GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9c51a-96f8-4817-ac6e-dfb8df82db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df1 = pd_merge_wo_nan.copy()\n",
    "\n",
    "\n",
    "\n",
    "Q1 = df1['GAP_corrected'].quantile(0.25)\n",
    "Q3 = df1['GAP_corrected'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.0 * IQR\n",
    "upper_bound = Q3 + 1.0 * IQR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "df1 = df1[(df1['GAP_corrected'] >= lower_bound) & (df1['GAP_corrected'] <= upper_bound)]\n",
    "\n",
    "\n",
    "bins = [0, df1['GDP_percapita'].median(), float('inf')]  \n",
    "labels = ['L_GDP', 'H_GDP']\n",
    "df1['Group_GDP'] = pd.cut(df1['GDP_percapita'], bins=bins, labels=labels)\n",
    "\n",
    "df1.dropna(subset = ['Group_GDP'], inplace = True)\n",
    "\n",
    "df1['SES_b'] = np.where(\n",
    "    df1['SES'] > df1['SES_wo_w'].median(), 'Hses',\n",
    "    np.where(\n",
    "        df1['SES'] <= df1['SES_wo_w'].median(), 'Lses',\n",
    "        np.nan\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "df1[\"Group_Combination\"] = df1[\"Group_GDP\"].astype(str) + \"_\" + df1[\"SES_b\"].astype(str)\n",
    "\n",
    "order = ['H_GDP_Lses', 'L_GDP_Lses', 'L_GDP_Hses',  'H_GDP_Hses']\n",
    "\n",
    "regions = ['H_GDP_Lses', 'L_GDP_Lses', 'L_GDP_Hses',  'H_GDP_Hses']\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = df1[df1['Group_Combination'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = df1[df1['Group_Combination'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "\n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        #print(f\"\\nTamaño del efecto de Cohen's d: {cohen_d:.3f}\")\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "sns.violinplot(x='Group_Combination', y='GAP_corrected', data=df1, order=order, palette=\"gray\", inner=\"box\")\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Región', fontsize=12)\n",
    "plt.ylabel('GAP Corrected', fontsize=12)\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylim([-20, 20])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85793b16-de83-4b38-8767-a6a8abb83f47",
   "metadata": {},
   "source": [
    "#### GNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f425ac59-e65d-4d48-81b6-b02dbe744aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df1 = pd_merge_wo_nan.copy()\n",
    "\n",
    "\n",
    "\n",
    "Q1 = df1['GAP_corrected'].quantile(0.25)\n",
    "Q3 = df1['GAP_corrected'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.0 * IQR\n",
    "upper_bound = Q3 + 1.0 * IQR\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "df1 = df1[(df1['GAP_corrected'] >= lower_bound) & (df1['GAP_corrected'] <= upper_bound)]\n",
    "\n",
    "\n",
    "df1['Income_v1'] = df1['Income'] \n",
    "\n",
    "df1['SES_b'] = np.where(\n",
    "    df1['SES'] > df1['SES_wo_w'].median(), 'Hses',\n",
    "    np.where(\n",
    "        df1['SES'] <= df1['SES_wo_w'].median(), 'Lses',\n",
    "        np.nan\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "df1[\"Group_Combination\"] = df1[\"Income_v1\"].astype(str) + \"_\" + df1[\"SES_b\"].astype(str)\n",
    "\n",
    "order = ['H_Lses', 'H_Hses', 'L_Lses', 'L_Hses']\n",
    "\n",
    "regions = ['H_Lses', 'H_Hses', 'L_Lses', 'L_Hses']\n",
    "mann_whitney_results = []\n",
    "\n",
    "for i in range(len(regions)):\n",
    "    for j in range(i + 1, len(regions)):\n",
    "        region1_data = df1[df1['Group_Combination'] == regions[i]]['GAP_corrected']\n",
    "        region2_data = df1[df1['Group_Combination'] == regions[j]]['GAP_corrected']\n",
    "\n",
    "\n",
    "        sub_sample_size = np.min([int(region1_data.shape[0]*0.9), int(region2_data.shape[0]*0.9)])\n",
    "        region1_data = resample(region1_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "        region2_data = resample(region2_data, n_samples=sub_sample_size, replace=False, random_state=42)\n",
    "\n",
    "        stat, p_value = stats.mannwhitneyu(region1_data, region2_data, alternative='two-sided')\n",
    "        \n",
    "        cliff_d, cliff_ci = cliff_delta(np.array(region1_data), np.array(region2_data))\n",
    "        print( \"cliff delta\",cliff_d, cliff_ci)\n",
    "        \n",
    "        cliff_d05, cliff_ci05 = cliff_delta05(np.array(region1_data), np.array(region2_data))\n",
    "        cliff_d10, cliff_ci10 = cliff_delta10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        r_b = rank_biserial_from_u(np.array(region1_data), np.array(region2_data))\n",
    "        r_b10 = rank_biserial_from_u10(np.array(region1_data), np.array(region2_data))\n",
    "\n",
    "        print(f\"No parametric cliff_delta: {cliff_d:.3f}\")\n",
    "\n",
    "        p_value_ = permtest(region1_data, region2_data)\n",
    "        mann_whitney_results.append((regions[i], regions[j], cliff_d, cliff_ci, cliff_d05, cliff_ci05, cliff_d10, r_b10, cliff_ci10, p_value_*len(regions), p_value*len(regions)))\n",
    "\n",
    "\n",
    "results_list = []\n",
    "for result in mann_whitney_results:\n",
    "\n",
    "    result_dict = {\n",
    "        \"Group1\": result[0],\n",
    "        \"Group2\": result[1],\n",
    "        \"cliff_delta 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[2]),\n",
    "        \"CI 0.1*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[3]),\n",
    "        \"cliff_delta 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[4]),\n",
    "        \"CI 0.5*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[5]),\n",
    "        \"cliff_delta 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[6]),\n",
    "        \"CI 1.0*IQR (0.15_S | 0.33_M | 0.47_L)\": np.abs(result[7]),\n",
    "        \"p-value 100000 perm\": np.abs(result[8]),\n",
    "        \"p-value mann whitney\": np.abs(result[9]),\n",
    "    }\n",
    "    results_list.append(result_dict)\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n",
    "display(results_df)\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.figure(figsize=(5, 4))\n",
    "\n",
    "sns.violinplot(x='Group_Combination', y='GAP_corrected', data=df1, order=order, palette=\"gray\", inner=\"box\")\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Región', fontsize=12)\n",
    "plt.ylabel('GAP Corrected', fontsize=12)\n",
    "plt.xticks(rotation=45, fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.ylim([-20, 20])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0c461-15cf-4990-9212-3294c329c54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9e5356-50a3-4628-9b72-5f129f25fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21fc99d-696f-4d12-95b9-0d11a41eb981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37a7758-23eb-4d03-a4c8-928f1dc1c19b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
